<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../../img/favicon.ico">
        <title>vortex.core.pipelines - Vortex</title>
        <link href="../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../css/font-awesome.min.css" rel="stylesheet">
        <link href="../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/ir-black.min.css">

        <script src="../../js/jquery-1.10.2.min.js" defer></script>
        <script src="../../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/console.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="../..">Vortex</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href="../.." class="nav-link">Home</a>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">User Guides <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../user-guides/dataset_integration/" class="dropdown-item">Dataset Integration</a>
</li>
                                    
<li>
    <a href="../../user-guides/experiment_file_config/" class="dropdown-item">Experiment File Configuration</a>
</li>
                                    
<li>
    <a href="../../user-guides/hypopt_file_config/" class="dropdown-item">HypOpt File Configuration</a>
</li>
                                    
<li>
    <a href="../../user-guides/pipelines/" class="dropdown-item">Pipelines</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Modules <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../modules/builtin_dataset/" class="dropdown-item">Built-in Dataset</a>
</li>
                                    
<li>
    <a href="../../modules/logging_provider/" class="dropdown-item">Logging Provider</a>
</li>
                                    
<li>
    <a href="../../modules/augmentation/" class="dropdown-item">Augmentations</a>
</li>
                                    
<li>
    <a href="../../modules/data_loader/" class="dropdown-item">Data Loader</a>
</li>
                                    
<li>
    <a href="../../modules/scheduler/" class="dropdown-item">Learning Rates Scheduler</a>
</li>
                                    
<li>
    <a href="../../modules/train_driver/" class="dropdown-item">Training Driver</a>
</li>
                                    
<li>
    <a href="../../modules/models_zoo/" class="dropdown-item">Models Zoo</a>
</li>
                                    
<li>
    <a href="../../modules/backbones/" class="dropdown-item">Backbones Network</a>
</li>
                                    
<li>
    <a href="../../modules/exporter/" class="dropdown-item">Graph Exporter</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown active">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">API <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="./" class="dropdown-item active">vortex.core.pipelines</a>
</li>
                                </ul>
                            </li>
                            <li class="navitem">
                                <a href="https://github.com/nodefluxio/vortex" class="nav-link">Repository</a>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../../modules/exporter/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" class="nav-link disabled">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#vortexcorepipelines" class="nav-link">vortex.core.pipelines</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#classes" class="nav-link">Classes</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="3"><a href="#graphexportpipeline" class="nav-link">GraphExportPipeline</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="3"><a href="#hypoptpipeline" class="nav-link">HypOptPipeline</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="3"><a href="#pytorchpredictionpipeline" class="nav-link">PytorchPredictionPipeline</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="3"><a href="#irpredictionpipeline" class="nav-link">IRPredictionPipeline</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="3"><a href="#trainingpipeline" class="nav-link">TrainingPipeline</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="3"><a href="#pytorchvalidationpipeline" class="nav-link">PytorchValidationPipeline</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="3"><a href="#irvalidationpipeline" class="nav-link">IRValidationPipeline</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="vortexcorepipelines">vortex.core.pipelines<a class="headerlink" href="#vortexcorepipelines" title="Permanent link">&para;</a></h1>
<hr />
<hr />
<h2 id="classes">Classes<a class="headerlink" href="#classes" title="Permanent link">&para;</a></h2>
<hr />
<hr />
<h3 id="graphexportpipeline">GraphExportPipeline<a class="headerlink" href="#graphexportpipeline" title="Permanent link">&para;</a></h3>
<p>Vortex Graph Export Pipeline API</p>
<h4 id="__init__"><code>__init__</code><a class="headerlink" href="#__init__" title="Permanent link">&para;</a></h4>
<pre><code class="python">def __init__(
      self,
      config : easydict.EasyDict,
      weights : typing.Union[str, pathlib.Path, NoneType] = None,
)
</code></pre>

<p><strong>Arguments</strong>:</p>
<ul>
<li><code>config</code> <em>EasyDict</em> - dictionary parsed from Vortex experiment file</li>
<li><code>weights</code> <em>Union[str,Path,None], optional</em> - path to selected Vortex model's weight. If set to None, it will                                                       assume that final model weights exist in <strong>experiment directory</strong>.                                                       Defaults to None.</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="python">from vortex.utils.parser import load_config
from vortex.core.pipelines import GraphExportPipeline

# Parse config
config = load_config('experiments/config/example.yml')
graph_exporter=GraphExportPipeline(config=config,weights='experiments/outputs/example/example.pth')
</code></pre>

<hr />
<h4 id="run"><code>run</code><a class="headerlink" href="#run" title="Permanent link">&para;</a></h4>
<pre><code class="python">def run(
      self,
      example_input : typing.Union[str, pathlib.Path, NoneType] = None,
)
</code></pre>

<p><strong>Arguments</strong>:</p>
<ul>
<li><code>example_input</code> <em>Union[str,Path,None], optional</em> - path to example input image to help graph tracing. Defaults to None.</li>
</ul>
<p><strong>Returns</strong>:</p>
<ul>
<li><code>EasyDict</code> - dictionary containing status of the export process</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="python">example_input = 'image1.jpg'
graph_exporter = GraphExportPipeline(config=config,
                                     weights='experiments/outputs/example/example.pth')

result = graph_exporter.run(example_input=example_input)
</code></pre>

<hr />
<hr />
<h3 id="hypoptpipeline">HypOptPipeline<a class="headerlink" href="#hypoptpipeline" title="Permanent link">&para;</a></h3>
<p>Vortex Hyperparameters Optimization Pipeline API</p>
<h4 id="__init___1"><code>__init__</code><a class="headerlink" href="#__init___1" title="Permanent link">&para;</a></h4>
<pre><code class="python">def __init__(
      self,
      config : easydict.EasyDict,
      optconfig : easydict.EasyDict,
      weights : typing.Union[str, pathlib.Path, NoneType] = None,
)
</code></pre>

<p><strong>Arguments</strong>:</p>
<ul>
<li><code>config</code> <em>EasyDict</em> - dictionary parsed from Vortex experiment file</li>
<li><code>optconfig</code> <em>EasyDict</em> - dictionary parsed from Vortex hypopt configuration file</li>
<li><code>weights</code> <em>Union[str,Path,None], optional</em> - path to selected Vortex model's weight. If set to None, it will                                                       assume that final model weights exist in <strong>experiment directory</strong>.                                                       Only used for ValidationObjective. Defaults to None.</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="python">from vortex.core.pipelines import HypOptPipeline
from vortex.utils.parser.loader import Loader
import yaml

# Parse config
config_path = 'experiments/config/example.yml'
optconfig_path = 'experiments/hypopt/learning_rate_search.yml'

with open(config_path) as f:
    config_data = yaml.load(f, Loader=Loader)
with open(optconfig_path) as f:
    optconfig_data = yaml.load(f, Loader=Loader)

graph_exporter=HypOptPipeline(config=config,optconfig=optconfig)
</code></pre>

<hr />
<h4 id="run_1"><code>run</code><a class="headerlink" href="#run_1" title="Permanent link">&para;</a></h4>
<pre><code class="python">def run(
      self,
)
</code></pre>

<p><strong>Returns</strong>:</p>
<ul>
<li><code>EasyDict</code> - dictionary containing result of the hypopt process</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="python">graph_exporter=HypOptPipeline(config=config,optconfig=optconfig)
results=graph_exporter.run()
</code></pre>

<hr />
<hr />
<h3 id="pytorchpredictionpipeline">PytorchPredictionPipeline<a class="headerlink" href="#pytorchpredictionpipeline" title="Permanent link">&para;</a></h3>
<p>Vortex Prediction Pipeline API for Vortex model</p>
<h4 id="__init___2"><code>__init__</code><a class="headerlink" href="#__init___2" title="Permanent link">&para;</a></h4>
<pre><code class="python">def __init__(
      self,
      config : easydict.EasyDict,
      weights : typing.Union[str, pathlib.Path, NoneType] = None,
      device : typing.Union[str, NoneType] = None,
)
</code></pre>

<p><strong>Arguments</strong>:</p>
<ul>
<li><code>config</code> <em>EasyDict</em> - dictionary parsed from Vortex experiment file</li>
<li><code>weights</code> <em>Union[str,Path,None], optional</em> - path to selected Vortex model's weight. If set to None, it will                                                       assume that final model weights exist in <strong>experiment directory</strong>.                                                       Defaults to None.</li>
<li><code>device</code> <em>Union[str,None], optional</em> - selected device for model's computation. If None, it will use the device                                                 described in <strong>experiment file</strong>. Defaults to None.</li>
</ul>
<p><strong>Raises</strong>:</p>
<ul>
<li><code>FileNotFoundError</code> - raise error if selected 'weights' file is not found</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="python">from vortex.core.pipelines import PytorchPredictionPipeline
from vortex.utils.parser import load_config

# Parse config
config_path = 'experiments/config/example.yml'
config = load_config(config_path)
weights_file = 'experiments/outputs/example/example.pth'
device = 'cuda'

vortex_predictor=PytorchPredictionPipeline(config = config,
                                           weights = weights_file,
                                           device = device)
</code></pre>

<hr />
<h4 id="run_2"><code>run</code><a class="headerlink" href="#run_2" title="Permanent link">&para;</a></h4>
<pre><code class="python">def run(
      self,
      images : typing.Union[typing.List[str], numpy.ndarray],
      visualize : bool = False,
      dump_visual : bool = False,
      output_dir : typing.Union[str, pathlib.Path] = '.',
      **kwargs,
)
</code></pre>

<p><strong>Arguments</strong>:</p>
<ul>
<li><code>images</code> <em>Union[List[str],np.ndarray]</em> - list of images path or array of image</li>
<li><code>visualize</code> <em>bool, optional</em> - option to return prediction visualization. Defaults to False.</li>
<li><code>dump_visual</code> <em>bool, optional</em> - option to dump prediction visualization. Defaults to False.</li>
<li><code>output_dir</code> <em>Union[str,Path], optional</em> - directory path to dump visualization. Defaults to '.' .</li>
<li><code>kwargs</code> <em>optional</em> - this kwargs is placement for additional input parameters specific to                                 models'task</li>
</ul>
<p><strong>Returns</strong>:</p>
<ul>
<li><code>EasyDict</code> - dictionary of prediction result</li>
</ul>
<p><strong>Raises</strong>:</p>
<ul>
<li><code>TypeError</code> - raise error if provided 'images' is not list of image path or array of images</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="python">
# Initialize prediction pipeline
vortex_predictor=PytorchPredictionPipeline(config = config,
                                           weights = weights_file,
                                           device = device)

### TODO: adding 'input_specs'

## OR
vortex_predictor=IRPredictionPipeline(model = model_file,
                                      runtime = runtime)

### You can get model's required parameter by extracting
### model's 'input_specs' attributes

input_shape  = vortex_predictor.model.input_specs.shape
additional_run_params = [key for key in vortex_predictor.model.input_specs.keys() if key!='input']
print(additional_run_params)

#### Assume that the model is detection model
#### ['score_threshold', 'iou_threshold'] &lt;&lt; this parameter must be provided in run() arguments

# Prepare batched input
batch_input = ['image1.jpg','image2.jpg']

## OR
import cv2
batch_input = np.array([cv2.imread('image1.jpg'),cv2.imread('image2.jpg')])

results = vortex_predictor.run(images=batch_input,
                               score_threshold=0.9,
                               iou_threshold=0.2)
</code></pre>

<hr />
<hr />
<h3 id="irpredictionpipeline">IRPredictionPipeline<a class="headerlink" href="#irpredictionpipeline" title="Permanent link">&para;</a></h3>
<p>Vortex Prediction Pipeline API for Vortex IR model</p>
<h4 id="__init___3"><code>__init__</code><a class="headerlink" href="#__init___3" title="Permanent link">&para;</a></h4>
<pre><code class="python">def __init__(
      self,
      model : typing.Union[str, pathlib.Path],
      runtime : str = 'cpu',
)
</code></pre>

<p><strong>Arguments</strong>:</p>
<ul>
<li><code>model</code> <em>Union[str,Path]</em> - path to Vortex IR model, file with extension '.onnx' or '.pt'</li>
<li><code>runtime</code> <em>str, optional</em> - backend runtime to be selected for model's computation. Defaults to 'cpu'.</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="python">from vortex.core.pipelines import IRPredictionPipeline
from vortex.utils.parser import load_config

# Parse config
model_file = 'experiments/outputs/example/example.pt' # Model file with extension '.onnx' or '.pt'
runtime = 'cpu'

vortex_predictor=IRPredictionPipeline(model = model_file,
                                      runtime = runtime)
</code></pre>

<hr />
<h4 id="run_3"><code>run</code><a class="headerlink" href="#run_3" title="Permanent link">&para;</a></h4>
<pre><code class="python">def run(
      self,
      images : typing.Union[typing.List[str], numpy.ndarray],
      visualize : bool = False,
      dump_visual : bool = False,
      output_dir : typing.Union[str, pathlib.Path] = '.',
      **kwargs,
)
</code></pre>

<p><strong>Arguments</strong>:</p>
<ul>
<li><code>images</code> <em>Union[List[str],np.ndarray]</em> - list of images path or array of image</li>
<li><code>visualize</code> <em>bool, optional</em> - option to return prediction visualization. Defaults to False.</li>
<li><code>dump_visual</code> <em>bool, optional</em> - option to dump prediction visualization. Defaults to False.</li>
<li><code>output_dir</code> <em>Union[str,Path], optional</em> - directory path to dump visualization. Defaults to '.' .</li>
<li><code>kwargs</code> <em>optional</em> - this kwargs is placement for additional input parameters specific to                                 models'task</li>
</ul>
<p><strong>Returns</strong>:</p>
<ul>
<li><code>EasyDict</code> - dictionary of prediction result</li>
</ul>
<p><strong>Raises</strong>:</p>
<ul>
<li><code>TypeError</code> - raise error if provided 'images' is not list of image path or array of images</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="python">
# Initialize prediction pipeline
vortex_predictor=PytorchPredictionPipeline(config = config,
                                           weights = weights_file,
                                           device = device)

### TODO: adding 'input_specs'

## OR
vortex_predictor=IRPredictionPipeline(model = model_file,
                                      runtime = runtime)

### You can get model's required parameter by extracting
### model's 'input_specs' attributes

input_shape  = vortex_predictor.model.input_specs.shape
additional_run_params = [key for key in vortex_predictor.model.input_specs.keys() if key!='input']
print(additional_run_params)

#### Assume that the model is detection model
#### ['score_threshold', 'iou_threshold'] &lt;&lt; this parameter must be provided in run() arguments

# Prepare batched input
batch_input = ['image1.jpg','image2.jpg']

## OR
import cv2
batch_input = np.array([cv2.imread('image1.jpg'),cv2.imread('image2.jpg')])

results = vortex_predictor.run(images=batch_input,
                               score_threshold=0.9,
                               iou_threshold=0.2)
</code></pre>

<hr />
<h4 id="runtime_predict"><code>runtime_predict</code><a class="headerlink" href="#runtime_predict" title="Permanent link">&para;</a></h4>
<pre><code class="python">def runtime_predict(
      predictor,
      image : numpy.ndarray,
      **kwargs,
)
</code></pre>

<p><strong>Arguments</strong>:</p>
<ul>
<li><code>predictor</code>- Vortex runtime object</li>
<li><code>image</code> <em>np.ndarray</em> - array of batched input image(s) with dimension of 4 (n,h,w,c)</li>
<li><code>kwargs</code> <em>optional</em> - this kwargs is placement for additional input parameters specific to                                 models'task</li>
</ul>
<p><strong>Returns</strong>:</p>
<ul>
<li><code>List</code> - list of prediction results</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="python">from vortex.core.factory import create_runtime_model
from vortex.core.pipelines import IRPredictionPipeline
import cv2

model_file = 'experiments/outputs/example/example_bs2.pt' # Model file with extension '.onnx' or '.pt'
runtime = 'cpu'
model = create_runtime_model(model_file, runtime)

batch_imgs = np.array([cv2.imread('image1.jpg'),cv2.imread('image2.jpg')])

results = IRPredictionPipeline.runtime_predict(model, 
                                               batch_imgs,
                                               score_threshold=0.9,
                                               iou_threshold=0.2
                                               )
</code></pre>

<hr />
<hr />
<h3 id="trainingpipeline">TrainingPipeline<a class="headerlink" href="#trainingpipeline" title="Permanent link">&para;</a></h3>
<p>Vortex Training Pipeline API</p>
<h4 id="__init___4"><code>__init__</code><a class="headerlink" href="#__init___4" title="Permanent link">&para;</a></h4>
<pre><code class="python">def __init__(
      self,
      config : easydict.EasyDict,
      config_path : typing.Union[str, pathlib.Path, NoneType] = None,
      hypopt : bool = False,
)
</code></pre>

<p><strong>Arguments</strong>:</p>
<ul>
<li><code>config</code> <em>EasyDict</em> - dictionary parsed from Vortex experiment file</li>
<li><code>config_path</code> <em>Union[str,Path,None], optional</em> - path to experiment file. Need to be provided for                                                           backup <strong>experiment file</strong>. Defaults to None.</li>
<li><code>hypopt</code> <em>bool, optional</em> - flag for hypopt, disable several pipeline process. Defaults to False.</li>
</ul>
<p><strong>Raises</strong>:</p>
<ul>
<li><code>Exception</code> - raise undocumented error if exist</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="python">from vortex.utils.parser import load_config
from vortex.core.pipelines import TrainingPipeline

# Parse config
config_path = 'experiments/config/example.yml'
config = load_config(config_path)
train_executor = TrainingPipeline(config=config,config_path=config_path,hypopt=False)
</code></pre>

<hr />
<h4 id="run_4"><code>run</code><a class="headerlink" href="#run_4" title="Permanent link">&para;</a></h4>
<pre><code class="python">def run(
      self,
      save_model : bool = True,
)
</code></pre>

<p><strong>Arguments</strong>:</p>
<ul>
<li><code>save_model</code> <em>bool, optional</em> - dump model's checkpoint. Defaults to True.</li>
</ul>
<p><strong>Returns</strong>:</p>
<ul>
<li><code>EasyDict</code> - dictionary containing loss, val results and learning rates history</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="python">train_executor = TrainingPipeline(config=config,config_path=config_path,hypopt=False)
outputs = train_executor.run()
</code></pre>

<hr />
<hr />
<h3 id="pytorchvalidationpipeline">PytorchValidationPipeline<a class="headerlink" href="#pytorchvalidationpipeline" title="Permanent link">&para;</a></h3>
<p>Vortex Validation Pipeline API for Vortex model</p>
<h4 id="__init___5"><code>__init__</code><a class="headerlink" href="#__init___5" title="Permanent link">&para;</a></h4>
<pre><code class="python">def __init__(
      self,
      config : easydict.EasyDict,
      weights : typing.Union[str, pathlib.Path, NoneType] = None,
      backends : typing.Union[list, str] = [],
      generate_report : bool = True,
      hypopt : bool = False,
)
</code></pre>

<p><strong>Arguments</strong>:</p>
<ul>
<li><code>config</code> <em>EasyDict</em> - dictionary parsed from Vortex experiment file</li>
<li><code>weights</code> <em>Union[str,Path,None], optional</em> - path to selected Vortex model's weight. If set to None, it will                                                       assume that final model weights exist in <strong>experiment directory</strong>.                                                       Defaults to None.</li>
<li><code>backends</code> <em>Union[list,str], optional</em> - device(s) to be used for validation process. If not provided,                                                   it will use the device described in <strong>experiment file</strong>. Defaults to [].</li>
<li><code>generate_report</code> <em>bool, optional</em> - if enabled will generate validation report in markdown format. Defaults to True.</li>
<li><code>hypopt</code> <em>bool, optional</em> - flag for hypopt, disable several pipeline process. Defaults to False.</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="python">from vortex.utils.parser import load_config
from vortex.core.pipelines import PytorchValidationPipeline

# Parse config
config_path = 'experiments/config/example.yml'
weights_file = 'experiments/outputs/example/example.pth'
backends = ['cpu','cuda']
config = load_config(config_path)
validation_executor = PytorchValidationPipeline(config=config,
                                                weights = weights_file,
                                                backends = backends,
                                                generate_report = True)
</code></pre>

<hr />
<h4 id="run_5"><code>run</code><a class="headerlink" href="#run_5" title="Permanent link">&para;</a></h4>
<pre><code class="python">def run(
      self,
      batch_size : int = 1,
)
</code></pre>

<p><strong>Arguments</strong>:</p>
<ul>
<li><code>batch_size</code> <em>int, optional</em> - size of validation input batch. Defaults to 1.</li>
</ul>
<p><strong>Returns</strong>:</p>
<ul>
<li><code>EasyDict</code> - dictionary containing validation metrics result</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="python">
# Initialize validation pipeline
validation_executor = PytorchValidationPipeline(config=config,
                                                weights = weights_file,
                                                backends = backends,
                                                generate_report = True)
## OR
validation_executor = IRValidationPipeline(config=config,
                                           model = model_file,
                                           backends = backends,
                                           generate_report = True)

# Run validation process
results = validation_executor.run(batch_size = 2)

## OR (Currently for IRValidationPipeline only)
## 'batch_size' information is also embedded in model.input_specs['input']['shape'][0]

batch_size = validation_executor.model.input_specs['input']['shape'][0]
results = validation_executor.run(batch_size = batch_size)
</code></pre>

<hr />
<hr />
<h3 id="irvalidationpipeline">IRValidationPipeline<a class="headerlink" href="#irvalidationpipeline" title="Permanent link">&para;</a></h3>
<p>Vortex Validation Pipeline API for Vortex IR model</p>
<h4 id="__init___6"><code>__init__</code><a class="headerlink" href="#__init___6" title="Permanent link">&para;</a></h4>
<pre><code class="python">def __init__(
      self,
      config : easydict.EasyDict,
      model : typing.Union[str, pathlib.Path, NoneType],
      backends : typing.Union[list, str] = ['cpu'],
      generate_report : bool = True,
      hypopt : bool = False,
)
</code></pre>

<p><strong>Arguments</strong>:</p>
<ul>
<li><code>config</code> <em>EasyDict</em> - ictionary parsed from Vortex experiment file</li>
<li><code>model</code> <em>Union[str,Path,None]</em> - path to Vortex IR model, file with extension '.onnx' or '.pt'</li>
<li><code>backends</code> <em>Union[list,str], optional</em> - runtime(s) to be used for validation process. Defaults to ['cpu'].</li>
<li><code>generate_report</code> <em>bool, optional</em> - if enabled will generate validation report in markdown format. Defaults to True.</li>
<li><code>hypopt</code> <em>bool, optional</em> - flag for hypopt, disable several pipeline process. Defaults to False.</li>
</ul>
<p><strong>Raises</strong>:</p>
<ul>
<li><code>RuntimeError</code> - raise error if the provided model file's extension is not '<em>.onnx' or '</em>.pt'</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="python">from vortex.utils.parser import load_config
from vortex.core.pipelines import IRValidationPipeline

# Parse config
config_path = 'experiments/config/example.yml'
model_file = 'experiments/outputs/example/example.pt'
backends = ['cpu','cuda']
config = load_config(config_path)
validation_executor = IRValidationPipeline(config=config,
                                           model = model_file,
                                           backends = backends,
                                           generate_report = True)
</code></pre>

<hr />
<h4 id="run_6"><code>run</code><a class="headerlink" href="#run_6" title="Permanent link">&para;</a></h4>
<pre><code class="python">def run(
      self,
      batch_size : int = 1,
)
</code></pre>

<p><strong>Arguments</strong>:</p>
<ul>
<li><code>batch_size</code> <em>int, optional</em> - size of validation input batch. Defaults to 1.</li>
</ul>
<p><strong>Returns</strong>:</p>
<ul>
<li><code>EasyDict</code> - dictionary containing validation metrics result</li>
</ul>
<p><strong>Examples</strong>:</p>
<pre><code class="python">
# Initialize validation pipeline
validation_executor = PytorchValidationPipeline(config=config,
                                                weights = weights_file,
                                                backends = backends,
                                                generate_report = True)
## OR
validation_executor = IRValidationPipeline(config=config,
                                           model = model_file,
                                           backends = backends,
                                           generate_report = True)

# Run validation process
results = validation_executor.run(batch_size = 2)

## OR (Currently for IRValidationPipeline only)
## 'batch_size' information is also embedded in model.input_specs['input']['shape'][0]

batch_size = validation_executor.model.input_specs['input']['shape'][0]
results = validation_executor.run(batch_size = batch_size)
</code></pre>

<hr /></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../js/base.js" defer></script>
        <script src="../../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
