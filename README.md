# Nodeflux Visual Cortex (Vortex)

Nodeflux Object Detection Training Framework

## How TO

## Full Documentations

check [Vortex Documentation](https://nodefluxio.github.io/vortex/)

### Run Unit Tests (with coverage)
- run `pytest` with `htmlcov` report :
```
pytest tests/
```
### Run CLI tools Tests :
- see [tests/cli/README.md](tests/cli/README.md)

### Installing System Dependencies
```
sudo apt update && sudo xargs apt install -y < requirements.sys
```

#### Additional Dependencies for Hyperparameter Optimization Visualization (Optional)
```
sudo apt update && sudo xargs apt install -y < optuna.vis.requirements.sys

sudo npm install -g electron@1.8.4 orca
```

### Install Python Package
```
pip3 install .
```
#### Install with Hyperparameter Optimization Visualization (Optional)
```
pip3 install .[optuna_vis]

```

## Tested Experiments
check [experiments/configs/README.md](experiments/configs/README.md)

## Command-Line Tools

After installing Python package, all available pipeline sub-command can be view by executing this command

```console
usage: vortex [-h]
              {train,validate,export,hypopt,predict,ir_runtime_predict,ir_runtime_validate}
              ...

Vortex CLI Development Tools

optional arguments:
  -h, --help            show this help message and exit

subcommands:
  Vortex pipeline stage selection

  {train,validate,export,hypopt,predict,ir_runtime_predict,ir_runtime_validate}
```


- [Training Pipeline](docs/user-guides/pipelines.md#training-pipeline)
  ```
  usage: vortex train [-h] -c CONFIG [--no-log]

  Vortex training pipeline; will generate a Pytorch model file

  optional arguments:
    -h, --help            show this help message and exit
    -c CONFIG, --config CONFIG
                          path to experiment config file
    --no-log              disable logging, ignore experiment file config
  ```
- [Validation Pipeline](docs/user-guides/pipelines.md#validation-pipeline)
  ```
  usage: vortex validate [-h] -c CONFIG [-w WEIGHTS] [-v] [--quiet]
                       [-d [DEVICES [DEVICES ...]]] [-b BATCH_SIZE]

  Vortex Pytorch model validation pipeline; successful runs will produce
  autogenerated reports

  optional arguments:
    -h, --help            show this help message and exit
    -c CONFIG, --config CONFIG
                          path to experiment config
    -w WEIGHTS, --weights WEIGHTS
                          path to selected weights(optional, will be inferred
                          from `output_directory` and `experiment_name` field
                          from config) if not specified
    -v, --verbose         verbose prediction output
    --quiet
    -d [DEVICES [DEVICES ...]], --devices [DEVICES [DEVICES ...]]
                          computation device to be used for prediction, possible
                          to list multiple devices
    -b BATCH_SIZE, --batch-size BATCH_SIZE
                          batch size for validation
  ```
  example
  ```
  vortex validate --config experiments/configs/shufflenetv2x100_retinaface_frontal_fddb_640.yml --batch-size 8
  ```
  after successful evaluation, report file will be generated under directory `reports` in the experiment directory based on `experiment_name` under `output_directory`.
  Pro Tip : the generated report could be easily converted to pdf using [pandoc](https://pandoc.org/demos.html) or [vscode markdown-pdf extension](https://marketplace.visualstudio.com/items?itemName=yzane.markdown-pdf).
- [Prediction Pipeline](docs/user-guides/pipelines.md#prediction-pipeline)
  ```
  usage: vortex predict [-h] -c CONFIG [-w WEIGHTS] [-o OUTPUT_DIR] -i IMAGE
                      [IMAGE ...] [-d DEVICE]
                      [--score_threshold SCORE_THRESHOLD]
                      [--iou_threshold IOU_THRESHOLD]

  Vortex Pytorch model prediction pipeline; may receive multiple image(s) for
  batched prediction

  optional arguments:
    -h, --help            show this help message and exit
    -c CONFIG, --config CONFIG
                          path to experiment config
    -w WEIGHTS, --weights WEIGHTS
                          path to selected weights(optional, will be inferred
                          from `output_directory` and `experiment_name` field
                          from config) if not specified
    -o OUTPUT_DIR, --output-dir OUTPUT_DIR
                          directory to dump prediction visualization
    -i IMAGE [IMAGE ...], --image IMAGE [IMAGE ...]
                          path to test image(s)
    -d DEVICE, --device DEVICE
                          the device in which the inference will be performed
    --score_threshold SCORE_THRESHOLD
                          score threshold for detection, only used if model is
                          detection, ignored otherwise
    --iou_threshold IOU_THRESHOLD
                          iou threshold for nms, only used if model is
                          detection, ignored otherwise
  ```
  example
  ```
  vortex predict --config experiments/configs/shufflenetv2x100_retinaface_frontal_fddb_640.yml --image tests/images/face.jpg tests/images/cat.jpg
  ```
  The generated visual result will be dumped under `--output-dir` arguments. By default this is set in the current working directory

- [Graph Export Pipeline](docs/user-guides/pipelines.md#graph-export-pipeline)
  ```
  usage: vortex export [-h] -c CONFIG [-w WEIGHTS] [-i EXAMPLE_INPUT]

  export model to specific IR specified in config, output IR are stored in the
  experiment directory based on `experiment_name` under `output_directory`
  config field, after successful export, you should be able to visualize the
  network using [netron](https://lutzroeder.github.io/netron/)

  optional arguments:
    -h, --help            show this help message and exit
    -c CONFIG, --config CONFIG
                          export experiment config file
    -w WEIGHTS, --weights WEIGHTS
                          path to selected weights (optional, will be inferred
                          from `output_directory` and `experiment_name` field
                          from config) if not specified
    -i EXAMPLE_INPUT, --example-input EXAMPLE_INPUT
                          path to example input for tracing (optional, may be
                          necessary for correct tracing, especially for
                          detection model)
  ```
  example
  ```
  vortex export --config experiments/configs/shufflenetv2x100_retinaface_frontal_fddb_640.yml --example-input tests/images/face.jpg
  ```
  LIMITATIONS :
  - for onnx model, check [COMPATIBILITY_REPORT_opset9.md](COMPATIBILITY_REPORT_opset9.md), [COMPATIBILITY_REPORT_opset10.md](COMPATIBILITY_REPORT_opset10.md), [COMPATIBILITY_REPORT_opset11.md](COMPATIBILITY_REPORT_opset11.md) for supported backbone-model and runtime env.   
  - for detection model, export to onnx supports multi-batch with `opset_version >= 11`

- [IR Runtime Prediction Pipeline](docs/user-guides/pipelines.md#ir-prediction-pipeline)
  ```
  usage: vortex ir_runtime_predict [-h] -m MODEL -i IMAGE [IMAGE ...]
                                 [-o OUTPUT_DIR]
                                 [--score_threshold SCORE_THRESHOLD]
                                 [--iou_threshold IOU_THRESHOLD] [-r RUNTIME]

  Vortex IR model prediction pipeline; may receive multiple image(s) for batched
  prediction

  optional arguments:
    -h, --help            show this help message and exit
    -m MODEL, --model MODEL
                          path to IR model
    -i IMAGE [IMAGE ...], --image IMAGE [IMAGE ...]
                          path to test image(s); at least 1 path should be
                          provided, supports up to model batch_size
    -o OUTPUT_DIR, --output-dir OUTPUT_DIR
                          directory to dump prediction visualization
    --score_threshold SCORE_THRESHOLD
                          score threshold for detection, only used if model is
                          detection, ignored otherwise
    --iou_threshold IOU_THRESHOLD
                          iou threshold for nms, only used if model is
                          detection, ignored otherwise
    -r RUNTIME, --runtime RUNTIME
                          runtime device

  ```
  example
  ```
  vortex ir_runtime_predict --model experiments/outputs/shufflenetv2x100_retinaface_frontal_fddb_640/shufflenetv2x100_retinaface_frontal_fddb_640_bs4.onnx --image tests/images/face.jpg tests/images/cat.jpg
  ```
  The generated visual result will be dumped under `--output-dir` arguments. By default this is set in the current working directory

- [IR Runtime Validation Pipeline](docs/user-guides/pipelines.md#ir-validation-pipeline)
  ```
  usage: vortex ir_runtime_validate [-h] -c CONFIG -m MODEL
                                  [-r [RUNTIME [RUNTIME ...]]] [-v] [--quiet]
                                  [--batch-size BATCH_SIZE]

  Vortex exported IR graph validation pipeline; successful runs will produce
  autogenerated reports

  optional arguments:
    -h, --help            show this help message and exit
    -c CONFIG, --config CONFIG
                          path to experiment config including dataset fields,
                          must be valid for validation, dataset.eval will be
                          used for evaluation
    -m MODEL, --model MODEL
                          path to IR model
    -r [RUNTIME [RUNTIME ...]], --runtime [RUNTIME [RUNTIME ...]]
                          runtime backend device
    -v, --verbose         verbose prediction output
    --quiet
    --batch-size BATCH_SIZE
                          batch size for validation; NOTE : passed value should
                          be matched with exported model batch size
  ```
  example 
  ```
  vortex ir_runtime_validate --model experiments/outputs/shufflenetv2x100_retinaface_frontal_fddb_640/shufflenetv2x100_retinaface_frontal_fddb_640_bs8.onnx --config experiments/configs/shufflenetv2x100_retinaface_frontal_fddb_640.yml --batch-size 8
  ```
  after successful evaluation, report file will be generated under directory `reports` in the experiment directory based on `experiment_name` under `output_directory`.
- [Hyperparameters Optimization Pipeline](docs/user-guides/pipelines.md#hyperparameters-optimization-pipeline)
  ```
  usage: vortex hypopt [-h] -c CONFIG -o OPTCONFIG [-w WEIGHTS]

  Vortex hyperparameter optimization experiment

  optional arguments:
    -h, --help            show this help message and exit
    -c CONFIG, --config CONFIG
                          path to experiment config file
    -o OPTCONFIG, --optconfig OPTCONFIG
                          path to hypopt config file
    -w WEIGHTS, --weights WEIGHTS
                          path to selected weights (optional, will be inferred
                          from `output_directory` and `experiment_name` field
                          from config) if not specified, valid only for
                          ValidationObjective, ignored otherwise
  ```
  example
  ```
  vortex hypopt --config experiments/configs/efficientnet_lite0_classification_stl10_224.yml --optconfig experiments/hypopt/learning_rate_search.yml
  ```
  ```
  vortex hypopt --config experiments/configs/shufflenetv2x100_retinaface_frontal_fddb_640.yml --optconfig experiments/hypopt/detection_param_search.yml
  ```
  ```
  vortex hypopt --config experiments/configs/shufflenetv2x100_retinaface_frontal_fddb_640.yml --optconfig experiments/hypopt/optimizer_search.yml
  ```